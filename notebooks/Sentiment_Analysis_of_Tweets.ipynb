{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis of Social Media During Health Crises\n",
    "## Archetype 3: The Socio-behavioral Scientist\n",
    "\n",
    "This notebook introduces sentiment analysis of social media data to understand public perceptions and behaviors during health crises. Students will analyze simulated tweet data to quantify public opinion over time and identify key themes like trust, fear, and misinformation.\n",
    "\n",
    "### Learning Objectives:\n",
    "- Understand how social media reflects and shapes public health behaviors\n",
    "- Learn natural language processing techniques for sentiment analysis\n",
    "- Analyze temporal patterns in public opinion during health crises\n",
    "- Identify factors that influence public trust and compliance\n",
    "- Connect social media sentiment to real-world health outcomes\n",
    "\n",
    "### Key Concepts:\n",
    "- **Risk perception**: How individuals assess and respond to health threats\n",
    "- **Health communication**: Strategies for conveying health information effectively\n",
    "- **Social amplification of risk**: How social processes can amplify or attenuate risk perceptions\n",
    "- **Infodemic**: Information epidemic that accompanies disease outbreaks\n",
    "- **Behavioral change models**: Frameworks for understanding health behavior adoption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import re\n",
    "import random\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# For text processing and sentiment analysis\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Download required NLTK data\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "except LookupError:\n",
    "    nltk.download('punkt')\n",
    "\n",
    "try:\n",
    "    nltk.data.find('corpora/stopwords')\n",
    "except LookupError:\n",
    "    nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"üì± Libraries loaded successfully for social media sentiment analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Understanding Social Media and Health Behavior\n",
    "\n",
    "Social media platforms have become primary sources of health information for many people. During health crises, these platforms can:\n",
    "\n",
    "1. **Spread accurate information** quickly to large audiences\n",
    "2. **Amplify misinformation** and conspiracy theories\n",
    "3. **Reflect public sentiment** and concerns in real-time\n",
    "4. **Influence health behaviors** through social proof and peer pressure\n",
    "5. **Create echo chambers** that reinforce existing beliefs\n",
    "\n",
    "Understanding these dynamics is crucial for public health communication and behavior change interventions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic tweet data simulating a vaccination campaign\n",
    "# This represents what you might collect from Twitter's API during a real health crisis\n",
    "\n",
    "def generate_synthetic_tweets(n_tweets=5000, duration_days=180):\n",
    "    \"\"\"\n",
    "    Generate synthetic tweet data for vaccination campaign analysis\n",
    "    \"\"\"\n",
    "    np.random.seed(42)  # For reproducibility\n",
    "    \n",
    "    # Define different phases of the vaccination campaign\n",
    "    phases = {\n",
    "        'announcement': {'days': (0, 30), 'sentiment_trend': 0.2, 'volume_multiplier': 1.5},\n",
    "        'early_rollout': {'days': (31, 90), 'sentiment_trend': -0.1, 'volume_multiplier': 2.0},\n",
    "        'side_effects_news': {'days': (91, 120), 'sentiment_trend': -0.4, 'volume_multiplier': 2.5},\n",
    "        'stabilization': {'days': (121, 180), 'sentiment_trend': 0.1, 'volume_multiplier': 1.2}\n",
    "    }\n",
    "    \n",
    "    # Template tweets for different sentiment categories\n",
    "    tweet_templates = {\n",
    "        'positive': [\n",
    "            \"Just got my vaccine! Feeling grateful for science and healthcare workers! üíâüôè #VaccinesWork\",\n",
    "            \"Vaccination sites are running smoothly. Great organization! #PublicHealth\",\n",
    "            \"So relieved to finally get vaccinated. Looking forward to seeing family again! #Hope\",\n",
    "            \"The vaccine gives me hope for the future. Science for the win! üß¨ #TrustScience\",\n",
    "            \"Proud to do my part to protect my community. #CommunityFirst #Vaccines\",\n",
    "            \"No side effects after my shot. Feel great! #VaccineExperience\",\n",
    "            \"Healthcare workers deserve all our gratitude. Thank you! üë©‚Äç‚öïÔ∏èüë®‚Äç‚öïÔ∏è #Heroes\"\n",
    "        ],\n",
    "        'negative': [\n",
    "            \"I'm worried about the long-term effects. Too rushed? #VaccineHesitancy\",\n",
    "            \"My friend had bad side effects. Makes me nervous... #Concerns\",\n",
    "            \"Why should I trust something developed so quickly? #Questions\",\n",
    "            \"Natural immunity is better than artificial. #NaturalHealth\",\n",
    "            \"The government shouldn't mandate medical procedures #Freedom\",\n",
    "            \"Too many conflicting messages from experts #Confusion\",\n",
    "            \"I'll wait and see what happens to others first #WaitAndSee\"\n",
    "        ],\n",
    "        'neutral': [\n",
    "            \"Vaccination appointment scheduled for next week. #Update\",\n",
    "            \"Looking into vaccine options available in my area #Research\",\n",
    "            \"Reading the latest studies on vaccine effectiveness #Science\",\n",
    "            \"Discussing vaccines with my doctor tomorrow #Healthcare\",\n",
    "            \"Vaccine rollout continues in our state #News\",\n",
    "            \"Different vaccines have different efficacy rates #Data\",\n",
    "            \"Checking eligibility requirements for vaccination #Info\"\n",
    "        ],\n",
    "        'fearful': [\n",
    "            \"I'm scared about potential side effects üò∞ #Fear\",\n",
    "            \"What if something goes wrong? So many unknowns... #Anxiety\",\n",
    "            \"Seeing reports of adverse events. Terrifying! #Scared\",\n",
    "            \"I don't know what to believe anymore üò¢ #Confused\",\n",
    "            \"This whole situation is overwhelming #Stress\",\n",
    "            \"Afraid of making the wrong choice for my family #ParentWorries\"\n",
    "        ],\n",
    "        'misinformation': [\n",
    "            \"Vaccines contain microchips for tracking #Conspiracy\",\n",
    "            \"Big pharma just wants to make money #FollowTheMoney\",\n",
    "            \"Vaccines cause autism - do your research! #Truth\",\n",
    "            \"This is all about population control #WakeUp\",\n",
    "            \"Natural remedies work better than vaccines #Alternative\",\n",
    "            \"The media is hiding vaccine deaths #CoverUp\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    tweets = []\n",
    "    start_date = datetime(2023, 1, 1)\n",
    "    \n",
    "    for day in range(duration_days):\n",
    "        current_date = start_date + timedelta(days=day)\n",
    "        \n",
    "        # Determine current phase\n",
    "        current_phase = None\n",
    "        for phase_name, phase_data in phases.items():\n",
    "            if phase_data['days'][0] <= day <= phase_data['days'][1]:\n",
    "                current_phase = phase_data\n",
    "                break\n",
    "        \n",
    "        # Base daily tweet volume\n",
    "        base_volume = int(n_tweets / duration_days)\n",
    "        daily_volume = int(base_volume * current_phase['volume_multiplier'])\n",
    "        \n",
    "        # Add some random variation\n",
    "        daily_volume = max(1, daily_volume + np.random.randint(-5, 5))\n",
    "        \n",
    "        for _ in range(daily_volume):\n",
    "            # Determine sentiment based on phase\n",
    "            sentiment_bias = current_phase['sentiment_trend']\n",
    "            \n",
    "            # Base probabilities for each sentiment\n",
    "            probs = {\n",
    "                'positive': 0.3 + sentiment_bias,\n",
    "                'negative': 0.25 - sentiment_bias/2,\n",
    "                'neutral': 0.25,\n",
    "                'fearful': 0.15 - sentiment_bias/3,\n",
    "                'misinformation': 0.05\n",
    "            }\n",
    "            \n",
    "            # Normalize probabilities\n",
    "            total = sum(probs.values())\n",
    "            probs = {k: max(0, v/total) for k, v in probs.items()}\n",
    "            \n",
    "            # Select sentiment category\n",
    "            sentiment_cat = np.random.choice(list(probs.keys()), p=list(probs.values()))\n",
    "            \n",
    "            # Select random tweet from category\n",
    "            tweet_text = np.random.choice(tweet_templates[sentiment_cat])\n",
    "            \n",
    "            # Add some variation to tweet text\n",
    "            variations = ['', ' ü§î', ' üí≠', ' üëç', ' üëé', ' ‚ù§Ô∏è', ' üò∑']\n",
    "            tweet_text += np.random.choice(variations)\n",
    "            \n",
    "            tweets.append({\n",
    "                'date': current_date,\n",
    "                'text': tweet_text,\n",
    "                'sentiment_category': sentiment_cat,\n",
    "                'day': day,\n",
    "                'phase': list(phases.keys())[list(phases.values()).index(current_phase)],\n",
    "                'user_id': f\"user_{np.random.randint(1, 1000)}\",\n",
    "                'retweets': np.random.poisson(5),\n",
    "                'likes': np.random.poisson(15)\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(tweets)\n",
    "\n",
    "# Generate the dataset\n",
    "tweets_df = generate_synthetic_tweets()\n",
    "print(f\"üìä Generated {len(tweets_df):,} synthetic tweets over {tweets_df['day'].max()+1} days\")\n",
    "print(f\"üóìÔ∏è Date range: {tweets_df['date'].min().date()} to {tweets_df['date'].max().date()}\")\n",
    "print(f\"\\nüìù Sample tweets:\")\n",
    "for i, row in tweets_df.sample(3).iterrows():\n",
    "    print(f\"- {row['text']} [{row['sentiment_category']}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Basic Text Processing and Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean and preprocess tweet text\n",
    "def clean_tweet_text(text):\n",
    "    \"\"\"\n",
    "    Clean tweet text for analysis\n",
    "    \"\"\"\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    \n",
    "    # Remove user mentions and hashtags for sentiment analysis (keep for keyword analysis)\n",
    "    text_for_sentiment = re.sub(r'@\\w+|#\\w+', '', text)\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    text_for_sentiment = ' '.join(text_for_sentiment.split())\n",
    "    \n",
    "    return text_for_sentiment.strip()\n",
    "\n",
    "# Function to extract hashtags\n",
    "def extract_hashtags(text):\n",
    "    \"\"\"\n",
    "    Extract hashtags from tweet text\n",
    "    \"\"\"\n",
    "    hashtags = re.findall(r'#\\w+', text.lower())\n",
    "    return hashtags\n",
    "\n",
    "# Function to calculate sentiment using TextBlob\n",
    "def analyze_sentiment(text):\n",
    "    \"\"\"\n",
    "    Analyze sentiment using TextBlob\n",
    "    Returns polarity (-1 to 1) and subjectivity (0 to 1)\n",
    "    \"\"\"\n",
    "    blob = TextBlob(text)\n",
    "    return blob.sentiment.polarity, blob.sentiment.subjectivity\n",
    "\n",
    "# Apply text processing\n",
    "tweets_df['cleaned_text'] = tweets_df['text'].apply(clean_tweet_text)\n",
    "tweets_df['hashtags'] = tweets_df['text'].apply(extract_hashtags)\n",
    "\n",
    "# Calculate sentiment scores\n",
    "sentiment_scores = tweets_df['cleaned_text'].apply(analyze_sentiment)\n",
    "tweets_df['polarity'] = [score[0] for score in sentiment_scores]\n",
    "tweets_df['subjectivity'] = [score[1] for score in sentiment_scores]\n",
    "\n",
    "# Categorize sentiment based on polarity\n",
    "def categorize_sentiment(polarity):\n",
    "    if polarity > 0.1:\n",
    "        return 'positive'\n",
    "    elif polarity < -0.1:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "tweets_df['sentiment_score'] = tweets_df['polarity'].apply(categorize_sentiment)\n",
    "\n",
    "print(\"‚úÖ Text processing and sentiment analysis completed\")\n",
    "print(f\"\\nüìà Sentiment Distribution:\")\n",
    "print(tweets_df['sentiment_score'].value_counts())\n",
    "\n",
    "# Show comparison between true categories and detected sentiment\n",
    "print(f\"\\nüéØ True vs Detected Sentiment (sample):\")\n",
    "comparison = tweets_df[['text', 'sentiment_category', 'sentiment_score', 'polarity']].sample(5)\n",
    "for _, row in comparison.iterrows():\n",
    "    print(f\"Text: {row['text'][:60]}...\")\n",
    "    print(f\"True: {row['sentiment_category']} | Detected: {row['sentiment_score']} | Score: {row['polarity']:.2f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Temporal Analysis of Public Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate sentiment by date\n",
    "daily_sentiment = tweets_df.groupby('date').agg({\n",
    "    'polarity': ['mean', 'std', 'count'],\n",
    "    'subjectivity': 'mean',\n",
    "    'sentiment_score': lambda x: (x == 'positive').sum() / len(x),  # Positive sentiment ratio\n",
    "    'retweets': 'sum',\n",
    "    'likes': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "# Flatten column names\n",
    "daily_sentiment.columns = ['date', 'mean_polarity', 'std_polarity', 'tweet_count', \n",
    "                          'mean_subjectivity', 'positive_ratio', 'total_retweets', 'total_likes']\n",
    "\n",
    "# Add rolling averages for smoother trends\n",
    "daily_sentiment['polarity_7day'] = daily_sentiment['mean_polarity'].rolling(window=7, center=True).mean()\n",
    "daily_sentiment['positive_ratio_7day'] = daily_sentiment['positive_ratio'].rolling(window=7, center=True).mean()\n",
    "\n",
    "# Create comprehensive temporal visualization\n",
    "fig, axes = plt.subplots(3, 2, figsize=(16, 15))\n",
    "\n",
    "# Plot 1: Daily sentiment polarity\n",
    "axes[0,0].plot(daily_sentiment['date'], daily_sentiment['mean_polarity'], \n",
    "               alpha=0.3, color='blue', label='Daily Average')\n",
    "axes[0,0].plot(daily_sentiment['date'], daily_sentiment['polarity_7day'], \n",
    "               color='red', linewidth=2, label='7-Day Moving Average')\n",
    "axes[0,0].axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "axes[0,0].set_ylabel('Sentiment Polarity')\n",
    "axes[0,0].set_title('Public Sentiment Over Time')\n",
    "axes[0,0].legend()\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Tweet volume\n",
    "axes[0,1].bar(daily_sentiment['date'], daily_sentiment['tweet_count'], \n",
    "              alpha=0.7, color='green')\n",
    "axes[0,1].set_ylabel('Number of Tweets')\n",
    "axes[0,1].set_title('Daily Tweet Volume')\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Positive sentiment ratio\n",
    "axes[1,0].plot(daily_sentiment['date'], daily_sentiment['positive_ratio'], \n",
    "               alpha=0.3, color='green', label='Daily Ratio')\n",
    "axes[1,0].plot(daily_sentiment['date'], daily_sentiment['positive_ratio_7day'], \n",
    "               color='darkgreen', linewidth=2, label='7-Day Moving Average')\n",
    "axes[1,0].set_ylabel('Positive Sentiment Ratio')\n",
    "axes[1,0].set_title('Proportion of Positive Tweets')\n",
    "axes[1,0].legend()\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Engagement metrics\n",
    "ax4_twin = axes[1,1].twinx()\n",
    "line1 = axes[1,1].plot(daily_sentiment['date'], daily_sentiment['total_retweets'], \n",
    "                       color='orange', label='Retweets')\n",
    "line2 = ax4_twin.plot(daily_sentiment['date'], daily_sentiment['total_likes'], \n",
    "                      color='red', label='Likes')\n",
    "axes[1,1].set_ylabel('Total Retweets', color='orange')\n",
    "ax4_twin.set_ylabel('Total Likes', color='red')\n",
    "axes[1,1].set_title('Daily Engagement Metrics')\n",
    "axes[1,1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 5: Sentiment distribution by phase\n",
    "phase_sentiment = tweets_df.groupby(['phase', 'sentiment_score']).size().unstack(fill_value=0)\n",
    "phase_sentiment_norm = phase_sentiment.div(phase_sentiment.sum(axis=1), axis=0)\n",
    "phase_sentiment_norm.plot(kind='bar', stacked=True, ax=axes[2,0], \n",
    "                         color=['red', 'gray', 'green'])\n",
    "axes[2,0].set_title('Sentiment Distribution by Campaign Phase')\n",
    "axes[2,0].set_ylabel('Proportion of Tweets')\n",
    "axes[2,0].tick_params(axis='x', rotation=45)\n",
    "axes[2,0].legend(title='Sentiment')\n",
    "\n",
    "# Plot 6: Subjectivity over time\n",
    "axes[2,1].plot(daily_sentiment['date'], daily_sentiment['mean_subjectivity'], \n",
    "               color='purple', linewidth=2)\n",
    "axes[2,1].set_ylabel('Mean Subjectivity')\n",
    "axes[2,1].set_title('Opinion vs Fact-based Content Over Time')\n",
    "axes[2,1].grid(True, alpha=0.3)\n",
    "\n",
    "# Add phase boundaries\n",
    "phase_dates = [datetime(2023, 1, 31), datetime(2023, 4, 1), datetime(2023, 5, 1)]\n",
    "phase_labels = ['Announcement', 'Early Rollout', 'Side Effects News', 'Stabilization']\n",
    "\n",
    "for i, ax_row in enumerate(axes):\n",
    "    for j, ax in enumerate(ax_row):\n",
    "        if i < 2:  # Don't add to bottom row plots\n",
    "            for date in phase_dates:\n",
    "                ax.axvline(x=date, color='gray', linestyle=':', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print key insights\n",
    "print(f\"\\nüìä Key Temporal Patterns:\")\n",
    "print(f\"Overall average sentiment: {daily_sentiment['mean_polarity'].mean():.3f}\")\n",
    "print(f\"Most positive day: {daily_sentiment.loc[daily_sentiment['mean_polarity'].idxmax(), 'date'].date()}\")\n",
    "print(f\"Most negative day: {daily_sentiment.loc[daily_sentiment['mean_polarity'].idxmin(), 'date'].date()}\")\n",
    "print(f\"Peak tweet volume: {daily_sentiment['tweet_count'].max()} tweets\")\n",
    "print(f\"Average positive tweet ratio: {daily_sentiment['positive_ratio'].mean():.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Hashtag Analysis and Theme Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze hashtag usage patterns\n",
    "all_hashtags = []\n",
    "for hashtag_list in tweets_df['hashtags']:\n",
    "    all_hashtags.extend(hashtag_list)\n",
    "\n",
    "hashtag_counts = Counter(all_hashtags)\n",
    "top_hashtags = hashtag_counts.most_common(20)\n",
    "\n",
    "print(f\"\\nüè∑Ô∏è Most Common Hashtags:\")\n",
    "for hashtag, count in top_hashtags[:10]:\n",
    "    print(f\"{hashtag}: {count:,} times\")\n",
    "\n",
    "# Analyze hashtag sentiment patterns\n",
    "hashtag_sentiment = {}\n",
    "for hashtag, count in top_hashtags:\n",
    "    if count >= 10:  # Only analyze hashtags with sufficient data\n",
    "        hashtag_tweets = tweets_df[tweets_df['hashtags'].apply(lambda x: hashtag in x)]\n",
    "        avg_sentiment = hashtag_tweets['polarity'].mean()\n",
    "        hashtag_sentiment[hashtag] = {\n",
    "            'count': count,\n",
    "            'avg_sentiment': avg_sentiment,\n",
    "            'pos_ratio': (hashtag_tweets['sentiment_score'] == 'positive').mean()\n",
    "        }\n",
    "\n",
    "# Create hashtag analysis visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Plot 1: Top hashtags by frequency\n",
    "hashtags, counts = zip(*top_hashtags[:15])\n",
    "axes[0,0].barh(range(len(hashtags)), counts, color='skyblue')\n",
    "axes[0,0].set_yticks(range(len(hashtags)))\n",
    "axes[0,0].set_yticklabels(hashtags)\n",
    "axes[0,0].set_xlabel('Frequency')\n",
    "axes[0,0].set_title('Most Frequently Used Hashtags')\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Hashtag sentiment analysis\n",
    "sentiment_hashtags = list(hashtag_sentiment.keys())\n",
    "sentiment_scores = [hashtag_sentiment[h]['avg_sentiment'] for h in sentiment_hashtags]\n",
    "sentiment_counts = [hashtag_sentiment[h]['count'] for h in sentiment_hashtags]\n",
    "\n",
    "scatter = axes[0,1].scatter(sentiment_scores, range(len(sentiment_hashtags)), \n",
    "                           s=[c/2 for c in sentiment_counts], alpha=0.6, c=sentiment_scores, \n",
    "                           cmap='RdYlGn')\n",
    "axes[0,1].set_yticks(range(len(sentiment_hashtags)))\n",
    "axes[0,1].set_yticklabels(sentiment_hashtags)\n",
    "axes[0,1].set_xlabel('Average Sentiment Score')\n",
    "axes[0,1].set_title('Hashtag Sentiment Analysis')\n",
    "axes[0,1].axvline(x=0, color='black', linestyle='--', alpha=0.5)\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "plt.colorbar(scatter, ax=axes[0,1])\n",
    "\n",
    "# Plot 3: Hashtag evolution over time\n",
    "key_hashtags = [h for h, c in top_hashtags[:5]]\n",
    "for hashtag in key_hashtags:\n",
    "    hashtag_data = tweets_df[tweets_df['hashtags'].apply(lambda x: hashtag in x)]\n",
    "    daily_counts = hashtag_data.groupby(hashtag_data['date'].dt.date).size()\n",
    "    axes[1,0].plot(daily_counts.index, daily_counts.values, label=hashtag)\n",
    "\n",
    "axes[1,0].set_xlabel('Date')\n",
    "axes[1,0].set_ylabel('Daily Frequency')\n",
    "axes[1,0].set_title('Hashtag Usage Over Time')\n",
    "axes[1,0].legend()\n",
    "axes[1,0].tick_params(axis='x', rotation=45)\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Word cloud of all hashtags\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white', \n",
    "                      colormap='viridis').generate_from_frequencies(hashtag_counts)\n",
    "axes[1,1].imshow(wordcloud, interpolation='bilinear')\n",
    "axes[1,1].set_title('Hashtag Word Cloud')\n",
    "axes[1,1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}